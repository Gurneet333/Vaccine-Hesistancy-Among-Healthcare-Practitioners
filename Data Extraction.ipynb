{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Name of Healthcare Workers from the subreddits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctors_df=pd.DataFrame(columns=['doctors_username','Qualification_flair','subreddit'])\n",
    "\n",
    "\n",
    "r = praw.Reddit(client_id= 'wsqr8yA-BU91oyCT91saQg',\n",
    "client_secret= 'Wjt-wkm00KSE1hOv1Ip1bCcBN7bO2w',\n",
    "user_agent= 'Test crawler')\n",
    "\n",
    "list_of_subreddits=['nurses','nursepractioner','doctors','PharmacyResidency','Mcat','premedcanada','mdphd','medschoolph','PAstudent','premeduk','SurgicalResidency','Cardiology','PharmacyTechnician','PharmacySchool','askdentists','anesthesiology','medicalschooluk','Chiropractic','PrePharmacy','pharmaindustry','TravelNursing']\n",
    "\n",
    "for subred in list_of_subreddits: \n",
    "    for submission in r.subreddit(subred).new(limit = 10000):\n",
    "\n",
    "        doctors_df=doctors_df.append({'doctors_username':submission.author,'Qualification_flair':submission.author_flair_text,'subreddit':subred}, ignore_index=True)\n",
    "\n",
    "doctors_df.to_csv(\"Doctors_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "doctors_df=pd.read_csv('Doctors_df.csv')\n",
    "\n",
    "#dividing the data into groups\n",
    "doctors_df['group_id']=(doctors_df.index / 100 + 1).astype(int)\n",
    "\n",
    "##Make the change here and mention group id\n",
    "\n",
    "doctors_df=doctors_df[doctors_df.group_id >= 15]\n",
    "doctors_df.head()\n",
    "\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "#get_ipython().run_line_magic('cd', '/Users/gauravchattree/Documents/Data_Mining_Project_2/Data_DL')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "#get_ipython().system('pip install psaw ')\n",
    "\n",
    "from psaw import PushshiftAPI\n",
    "\n",
    "fieldnames=[\"author\",\"author_flair_text\",\"author_flair_type\",\"body\",\"created_utc\",\"id\",\"is_submitter\",\"score\",\"subreddit\",\"subreddit_id\"]\n",
    "with open('DDDDoctors_comments_df2.csv', \"w\", newline=\"\") as csvfile:\n",
    "  writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "  writer.writeheader()\n",
    "\n",
    "\n",
    "start_epoch=int(dt(2020, 3, 1).timestamp()) #start_date\n",
    "end_epoch=int(dt(2021, 11,14 ).timestamp()) #end_date \n",
    "\n",
    "data = pd.DataFrame(columns =['author','author_flair_text','author_flair_type','body','created_utc','id','is_submitter','score','subreddit','subreddit_id'])\n",
    "\n",
    "api = PushshiftAPI() \n",
    "\n",
    "for a in doctors_df['group_id'].unique():\n",
    "    print(\"Running group id:\",a)\n",
    "    temp=doctors_df[doctors_df.group_id==a]\n",
    "    for username in temp['doctors_username']:\n",
    "        try:\n",
    "            gen = api.search_comments(author=username, after = start_epoch, before = end_epoch)\n",
    "            df2 = pd.DataFrame([thing.d_ for thing in gen])\n",
    "            print(\"Fetching comments of \",username)\n",
    "            df2=df2.loc[:,['author','author_flair_text','author_flair_type','body','created_utc','id','is_submitter','score','subreddit','subreddit_id']]\n",
    "            df2.to_csv('DDDDoctors_comments_df2.csv', mode='a',header=False)\n",
    "            data = data.append(df2[data.columns], ignore_index=True)\n",
    "          #time.sleep(5)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To extract comments from submissions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "reddit = praw.Reddit(client_id = \"wsqr8yA-BU91oyCT91saQg\",\n",
    "                     client_secret = \"Wjt-wkm00KSE1hOv1Ip1bCcBN7bO2w\",\n",
    "                     username = \"Gurneet30\",\n",
    "                     password = \"Rochester30\",\n",
    "                     user_agent = \"Test crawler\")\n",
    "submission = reddit.submission(id=\"r1bibk\")\n",
    "\n",
    "\n",
    "df_appended= pd.DataFrame(columns=['author', 'author_flair_text', 'body',\n",
    "       'created_utc', 'id', 'is_submitter', 'score', 'subreddit',\n",
    "       'subreddit_id'])\n",
    "\n",
    "headers=['author', 'author_flair_text', 'author_flair_type', 'body',\n",
    "      'created_utc', 'id', 'is_submitter', 'score', 'subreddit',\n",
    "      'subreddit_id']\n",
    "# -------------------------------------------------------------------\n",
    "submission.comments.replace_more(limit=None)\n",
    "for comment in submission.comments.list():\n",
    "    df_appended = df_appended.append({'author':comment.author,\n",
    "                                     'author_flair_text':comment.author_flair_text,\n",
    "                                      #'author_flair_type':comment.author_flair_type,\n",
    "                                      'body':comment.body,\n",
    "                                      'created_utc':comment.created_utc,\n",
    "                                      'id':comment.id,\n",
    "                                      'is_submitter':comment.is_submitter,\n",
    "                                      'score':comment.score,\n",
    "                                      'subreddit':comment.subreddit,\n",
    "                                      'subreddit_id':comment.subreddit_id       \n",
    "                                     },ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all the Raw Excels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list=[ 'Doctors_comments_df_100.csv',\t\n",
    "            'Doctors_comments_df2 (2).csv',\n",
    "            'Doctors_comments_df_120.csv',\n",
    "            'Doctors_comments_df_154.csv',\t \n",
    "            'Doctors_comments_df3.csv',\n",
    "            'Doctors_comments_df_182.csv',\n",
    "           \t'Doctors_comments_df4.csv',\n",
    "            'Doctors_comments_df_210.csv', \n",
    "            'Doctors_comments_df5.csv',\n",
    "            'Doctors_comments_df2 (1).csv',\n",
    "           \t'Doctors_comments_df.csv',\n",
    "            'Doctors_comments_df_225.csv',\n",
    "            'Doctors_comments_df6.csv',\n",
    "           'New_Doctors_comments_df_1_15.csv',\n",
    "           'New_Doctors_comments_df_16_20.csv',\n",
    "           'New_Doctors_comments_df_21_35.csv',\n",
    "           'New_Doctors_comments_df_31_34.csv',\n",
    "           'New_Doctors_comments_df_36_45.csv',\n",
    "           'New_Doctors_comments_df2_45.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading all the csv's\n",
    "\n",
    "df_appended= pd.DataFrame(columns=['author', 'author_flair_text', 'author_flair_type', 'body',\n",
    "       'created_utc', 'id', 'is_submitter', 'score', 'subreddit',\n",
    "       'subreddit_id'])\n",
    "\n",
    "for i in file_list:\n",
    "    print(i)\n",
    "    headers=['author', 'author_flair_text', 'author_flair_type', 'body',\n",
    "       'created_utc', 'id', 'is_submitter', 'score', 'subreddit',\n",
    "       'subreddit_id']\n",
    "\n",
    "    df_temp=pd.read_csv(i,names=headers,skiprows=1)\n",
    "    df_appended=df_appended.append(df_temp)\n",
    "    \n",
    "\n",
    "df_appended.to_pickle('fulldata_v2.pickle')\n",
    "df_appended=pd.read_pickle('fulldata_v2.pickle')\n",
    "\n",
    "#Dropping the duplicates\n",
    "\n",
    "df_appended=df_appended.drop_duplicates(subset=['body'])\n",
    "\n",
    "\n",
    "#df_appended['Covid_rel_bool']=\n",
    "#df_appended['covid_rel_bool']= \n",
    "df_appended=df_appended.dropna(subset = ['body'])\n",
    "df_appended['Index1'] = np.arange(df_appended.shape[0])\n",
    "\n",
    "## Save it as a pickle file\n",
    "df_appended.to_pickle('filterdata_v2.pickle')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating boolean columns of covid related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_appended=pd.read_pickle('filterdata_v2.pickle')\n",
    "\n",
    "df_appended1=df_appended.loc[:,['Index1','author','body']]\n",
    "del df_appended\n",
    "\n",
    "l1=['vaccine', 'vaccines', 'vaccinated', 'vaccination', 'vacinne', 'vacine', 'antivax','anti vax', 'immunization',\n",
    "    \n",
    "    'covid', 'covid-19', 'coronavirus', 'pandemic', \n",
    "\n",
    "    'MMR', 'autism', 'HPV', 'tuberculosis', 'tetanus', 'hepatitis B', 'flu shot','flu vaccine',\n",
    "\n",
    "    'pfizer','moderna','Pfizer-BioNTech','Johnson & Johnson’s Janssen','Janssen'\n",
    "    ]\n",
    "\n",
    "for i in l1:\n",
    "    df_appended1[i+'_bool']=df_appended1['body'].str.lower().str.contains(i).astype(int)\n",
    "\n",
    "\n",
    "corona_group=['covid_bool', 'covid-19_bool', 'coronavirus_bool', 'pandemic_bool']\n",
    "vaccine_group=['vaccine_bool', 'vaccines_bool', 'vaccinated_bool', 'vaccination_bool', 'vacinne_bool', 'vacine_bool','pfizer_bool','moderna_bool','Pfizer-BioNTech_bool','Johnson & Johnson’s Janssen_bool','Janssen_bool','antivax_bool','anti vax_bool','immunization_bool']\n",
    "other_vacc_group=['MMR_bool','autism_bool', 'HPV_bool', 'tuberculosis_bool', 'tetanus_bool', 'hepatitis B_bool', 'flu shot_bool','flu vaccine_bool']\n",
    "\n",
    "df_appended1['Corona_comb']= df_appended1[corona_group].max(axis=1)\n",
    "df_appended1['Vaccine_comb']= df_appended1[vaccine_group].max(axis=1)\n",
    "df_appended1['Other_Vaccine_comb']= df_appended1[other_vacc_group].max(axis=1)\n",
    "\n",
    "\n",
    "def net_vacc(df):\n",
    "    if df['Vaccine_comb']==1 and df['Other_Vaccine_comb']==0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "df_appended1['net_vacc_comb']=df_appended1.apply(lambda x: net_vacc(x), axis=1)\n",
    "df_appended1['Overall_bool']=df_appended1[['Corona_comb','net_vacc_comb']].max(axis=1)\n",
    "\n",
    "\n",
    "\n",
    "## Combining CSV's to get our final relevant data\n",
    "\n",
    "l2=['Preprocessed_v2_1_500000.csv','Preprocessed_v2_500000_1000000.csv','Preprocessed_v2_1000000_1500000.csv','Preprocessed_v2_1500000_2000000.csv','Preprocessed_v2_2000000_above.csv']\n",
    "\n",
    "df_processed=pd.DataFrame(columns=['Index1', 'author', 'body', 'vaccine_bool', 'vaccines_bool',\n",
    "       'vaccinated_bool', 'vaccination_bool', 'vacinne_bool', 'vacine_bool',\n",
    "       'antivax_bool', 'anti vax_bool', 'immunization_bool', 'covid_bool',\n",
    "       'covid-19_bool', 'coronavirus_bool', 'pandemic_bool', 'MMR_bool',\n",
    "       'autism_bool', 'HPV_bool', 'tuberculosis_bool', 'tetanus_bool',\n",
    "       'hepatitis B_bool', 'flu shot_bool', 'flu vaccine_bool', 'pfizer_bool',\n",
    "       'moderna_bool', 'Pfizer-BioNTech_bool',\n",
    "       'Johnson & Johnson’s Janssen_bool', 'Janssen_bool', 'Corona_comb',\n",
    "       'Vaccine_comb', 'Other_Vaccine_comb', 'net_vacc_comb', 'Overall_bool'])\n",
    "for i in l2:\n",
    "    temp=pd.read_csv(i)\n",
    "    df_processed=df_processed.append(temp)\n",
    "\n",
    "    \n",
    "df_processed.to_csv('RelevantData_v2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
